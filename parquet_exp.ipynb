{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEAARNING ABOUT THE PARQUT FILE FORMAT \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/11 10:28:50 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "# from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode\n",
    "spark=SparkSession.builder.appName(\"parquet-exp.com\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[\n",
    "    ((\"James\",\"\",\"Smith\"),[\"Java\",\"Scala\",\"C++\"],\"OH\",\"M\"),\n",
    "    ((\"Anna\",\"Rose\",\"\"),[\"Spark\",\"Java\",\"C++\"],\"NY\",\"F\"),\n",
    "    ((\"Julia\",\"\",\"Williams\"),[\"CSharp\",\"VB\"],\"OH\",\"F\"),\n",
    "    ((\"Maria\",\"Anne\",\"Jones\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
    "    ((\"Jen\",\"Mary\",\"Brown\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
    "    ((\"Mike\",\"Mary\",\"Williams\"),[\"Python\",\"VB\"],\"OH\",\"M\")\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n",
      "|                name|         languages|state|Gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|    {James, , Smith}|[Java, Scala, C++]|   OH|     M|\n",
      "|      {Anna, Rose, }|[Spark, Java, C++]|   NY|     F|\n",
      "| {Julia, , Williams}|      [CSharp, VB]|   OH|     F|\n",
      "|{Maria, Anne, Jones}|      [CSharp, VB]|   NY|     M|\n",
      "|  {Jen, Mary, Brown}|      [CSharp, VB]|   NY|     M|\n",
      "+--------------------+------------------+-----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns=[\"name\",\"languages\",\"state\",\"Gender\"]\n",
    "df=spark.createDataFrame(data=data,schema=columns)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.parquet(\"/home/ai/Downloads/Pyspark_learning/sampleparquet.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n",
      "|                name|         languages|state|Gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|{Mike, Mary, Will...|      [Python, VB]|   OH|     M|\n",
      "|{Maria, Anne, Jones}|      [CSharp, VB]|   NY|     M|\n",
      "| {Julia, , Williams}|      [CSharp, VB]|   OH|     F|\n",
      "|  {Jen, Mary, Brown}|      [CSharp, VB]|   NY|     M|\n",
      "|    {James, , Smith}|[Java, Scala, C++]|   OH|     M|\n",
      "|      {Anna, Rose, }|[Spark, Java, C++]|   NY|     F|\n",
      "+--------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2=spark.read.parquet(\"/home/ai/Downloads/Pyspark_learning/sampleparquet.parquet\")\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDF = [(('James','','Smith'),'1991-04-01','M',3000),\n",
    "  (('Michael','Rose',''),'2000-05-19','M',4000),\n",
    "  (('Robert','','Williams'),'1978-09-05','M',4000),\n",
    "  (('Maria','Anne','Jones'),'1967-12-01','F',4000),\n",
    "  (('Jen','Mary','Brown'),'1980-02-17','F',-1)\n",
    "  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "schema = StructType([\n",
    "        StructField('name', StructType([\n",
    "             StructField('firstname', StringType(), True),\n",
    "             StructField('middlename', StringType(), True),\n",
    "             StructField('lastname', StringType(), True)\n",
    "             ])),\n",
    "         StructField('dob', StringType(), True),\n",
    "         StructField('gender', StringType(), True),\n",
    "         StructField('Salary', IntegerType(), True)\n",
    "         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n",
      "+--------------------+----------+------+------+\n",
      "|                name|       dob|gender|Salary|\n",
      "+--------------------+----------+------+------+\n",
      "|    {James, , Smith}|1991-04-01|     M|  3000|\n",
      "|   {Michael, Rose, }|2000-05-19|     M|  4000|\n",
      "|{Robert, , Williams}|1978-09-05|     M|  4000|\n",
      "|{Maria, Anne, Jones}|1967-12-01|     F|  4000|\n",
      "|  {Jen, Mary, Brown}|1980-02-17|     F|    -1|\n",
      "+--------------------+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('parquetExamples.com').getOrCreate()\n",
    "df3 = spark.createDataFrame(data = dataDF, schema = schema)\n",
    "df3.printSchema()\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "appending the data from the new dataframe to the existing file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.write.parquet(\"/home/ai/Downloads/Pyspark_learning/sampleparquet1.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n",
      "|                name|         languages|state|Gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|{Mike, Mary, Will...|      [Python, VB]|   OH|     M|\n",
      "|{Maria, Anne, Jones}|      [CSharp, VB]|   NY|     M|\n",
      "| {Julia, , Williams}|      [CSharp, VB]|   OH|     F|\n",
      "|  {Jen, Mary, Brown}|      [CSharp, VB]|   NY|     M|\n",
      "|    {James, , Smith}|[Java, Scala, C++]|   OH|     M|\n",
      "|      {Anna, Rose, }|[Spark, Java, C++]|   NY|     F|\n",
      "+--------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.write.mode(\"append\").parquet(\"/home/ai/Downloads/Pyspark_learning/sampleparquet1.parquet\")\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the file has been appended since it has same schema but the stuctfield is different so it turns out to be null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark sql query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.createOrReplaceTempView(\"sampleParquet1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "parksql=spark.sql(\"select * from sampleParquet1 where salary>=4000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+------+------+\n",
      "|                name|       dob|gender|Salary|\n",
      "+--------------------+----------+------+------+\n",
      "|   {Michael, Rose, }|2000-05-19|     M|  4000|\n",
      "|{Robert, , Williams}|1978-09-05|     M|  4000|\n",
      "|{Maria, Anne, Jones}|1967-12-01|     F|  4000|\n",
      "+--------------------+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parksql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE TEMPORARY VIEW PERSONs USING parquet OPTIONS (path \\\"/home/ai/Downloads/Pyspark_learning/sampleparquet1.parquet\\\")\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('name', 'struct<firstname:string,middlename:string,lastname:string>'),\n",
       " ('dob', 'string'),\n",
       " ('gender', 'string'),\n",
       " ('Salary', 'int')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df3.select(explode(df3.name),df3.dob,df3.gender,df3.Salary)\n",
    "df3.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =[(\"James \",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
    "              (\"Michael \",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
    "              (\"Robert \",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
    "              (\"Maria \",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
    "              (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)]\n",
    "columns=[\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"]\n",
    "df4=spark.createDataFrame(data,columns)\n",
    "# <!-- above example, it creates a DataFrame with  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.write.parquet(\"/home/ai/Downloads/Pyspark_learning/partion.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.write.partitionBy(\"gender\",\"salary\").mode(\"overwrite\").parquet(\"/home/ai/Downloads/Pyspark_learning/partion.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----+------+------+\n",
      "|firstname|middlename|lastname|dob  |gender|salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|Maria    |Anne      |Jones   |39192|F     |4000  |\n",
      "|Robert   |          |Williams|42114|M     |4000  |\n",
      "|Michael  |Rose      |        |40288|M     |4000  |\n",
      "|James    |          |Smith   |36636|M     |3000  |\n",
      "|Jen      |Mary      |Brown   |     |F     |-1    |\n",
      "+---------+----------+--------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parDF2=spark.read.parquet(\"/home/ai/Downloads/Pyspark_learning/partion.parquet\")\n",
    "parDF2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE TEMPORARY VIEW PERSON2 USING parquet OPTIONS(path \\\"/home/ai/Downloads/Pyspark_learning/partion.parquet\\\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----+------+------+\n",
      "|firstname|middlename|lastname|  dob|gender|salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|   Maria |      Anne|   Jones|39192|     F|  4000|\n",
      "|  Robert |          |Williams|42114|     M|  4000|\n",
      "| Michael |      Rose|        |40288|     M|  4000|\n",
      "|   James |          |   Smith|36636|     M|  3000|\n",
      "|      Jen|      Mary|   Brown|     |     F|    -1|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from PERSON2\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
